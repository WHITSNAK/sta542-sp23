\documentclass[11pt, letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper, margin=0.5in]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{listings}
\usepackage[font=scriptsize]{caption}
\usepackage{subcaption}
\usepackage{xcolor}

\newtheorem{lemma}{Lemma}
\newcommand{\indep}{\perp \!\!\! \perp}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    texcl=true,
    mathescape=true,
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}
\graphicspath{ {.} }
\captionsetup{justification=raggedright, singlelinecheck=false}

\author{Ryan Tang}
\title{STA 542 HW 2}
\date{March 2nd 2023}

\begin{document}
\maketitle

\section{Ex 1}
Suppose we know the underlying truth $Y = X^2 + Z$. Both $X$ and $Z$ are standard normal $N(0,1)$ and independent of each other $X \indep Z$. Then the best predictor $E[Y|X] = X^2$. On the other hand, the best linear predictor is simply the expected mean of $Y$ because of the following.
\begin{align*}
    \text{Cov}(Y, X) &= \text{Cov}(X^2 + Z, X) \\
        &= \text{Cov}(X^2, X) + \text{Cov}(Z, X) \\
        &= E[X^3] - E[X]E[X^2] + 0 \\
        &= 0 \\
    E[Y \in \{\mathcal{M}: Y = a + bX\}|X] &= E[Y] = E[X^2] + E[Z] = 1
\end{align*}

\section{Ex 2}
\paragraph{(a)}
Here we plot $f(t) = A \cos(2\pi \times 5t + \alpha)$, where $A = \pi, \aplha = 1$ and between $0 < t \leq 5$ at 120Hz. The resulting $f_{478} = 2.324$.
\begin{align*}
    f_t = \pi \cos(2\pi \times 5t + 1)
\end{align*}

\begin{figure*}[!h]
  \centering
  \includegraphics[width=1.0\textwidth]{plot1.png}
  \captionsetup{justification=centering}
  \caption{The ground truth cosine wave}
\end{figure*}

\paragraph{(b)}
Now, we adds a $MA(2|\theta=(0.4, 1.6))$ noise to the ground truth with each individual $w_t \thicksim_{iid} N(0,v=1)$. Hence, we have $Y_t = f_t + X_t$. See Figure \ref{fig:truth_plus_noise}.

\begin{figure*}[!h]
  \centering
  \includegraphics[width=1.0\textwidth]{plot2.png}
  \captionsetup{justification=centering}
  \caption{The ground truth cosine wave plus MA(2) noises, $Y_t = f_t + X_t$}
  \label{fig:truth_plus_noise}
\end{figure*}

\paragraph{(c)}
Suppose we know $X_t$ follows MA(2) process and would like to estimate the coefficients directly from the observations $Y_t$. We get the following coefficients $\hat{\theta}=(0.76, 0.2523), \hat{v}=5.6$. Obviously, it is way off from the ground truth $\theta = (0.4 1.6), v=1$.

\paragraph{(d)}
We can also consider the ARIMA model, using the finite differences to remove and trend, $Z_t = (1-B)^d Y_t$. It is under the assumption that we can recover the stationary series after the finite differences. However, we know the underlying series; we can't arrive at anything stationary. For example, the first-order difference of $f_t$ gives us a mixture of two cosine waves at a different phase.
\begin{align*}
    (1-B)f_t &= f_t - f_{t-1} \\
        &= \pi [cos(2\pi \times 5t + 1) - cos(2\pi \times 5t - 4)]
\end{align*}



\end{document}